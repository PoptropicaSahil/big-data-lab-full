# -*- coding: utf-8 -*-
"""Project_BigDataLab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LmRRCdcGSyazmnUZOB08y006j6KY1N7l
"""

#Load the librarys
import pandas as pd #To work with dataset
import numpy as np #Math library
import seaborn as sns #Graph library that use matplot in background
import matplotlib.pyplot as plt #to plot some parameters in seaborn

#Importing the data
df_credit = pd.read_csv("german_credit_data.csv",index_col=0)

df_credit.head()

#Searching for Missings,type of data and also known the shape of data
print(df_credit.info())

#Looking unique values
print(df_credit.nunique())
#Looking the data
print(df_credit.head())

!pip install pyspark

# Import necessary libraries
from pyspark.sql import SparkSession
from pyspark.sql.functions import isnan, when, count, col

# Load the libraries
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when, count, countDistinct, lit

# Create a SparkSession
spark = SparkSession.builder.appName("CreditDataProcessing").getOrCreate()

# Load the dataset
df_credit = spark.read.csv("german_credit_data.csv", header=True, inferSchema=True)

# Rename columns to small caps
df_credit = df_credit.select([col(c).alias(c.lower()) for c in df_credit.columns])

# Rename the column "savings account" to "savings_account"
df_credit = df_credit.withColumnRenamed("saving accounts", "savings_account")
df_credit = df_credit.withColumnRenamed("checking account", "checking_account")
df_credit = df_credit.withColumnRenamed("credit amount", "credit_amount")

df_credit.head()

# Print schema to see the data types of all columns
df_credit.printSchema()

# Access the data type of a specific column
checking_account_data_type = df_credit.schema["checking_account"].dataType
print("Data type of checking_account column:", checking_account_data_type)

from pyspark.sql.functions import col, when, lit

# Fill missing NA values in "savings_account" and "checking_account" columns
most_freq_savings = df_credit.select("savings_account").groupBy("savings_account").agg(count("*").alias("count")).orderBy(col("count").desc()).collect()[0]["savings_account"]
most_freq_checking = df_credit.select("checking_account").groupBy("checking_account").agg(count("*").alias("count")).orderBy(col("count").desc()).collect()[1]["checking_account"]

# Replace "NA" with "Missing" in the "savings_account" column
df_credit = df_credit.withColumn("savings_account", when(col("savings_account") == "NA", most_freq_savings)
                                  .otherwise(col("savings_account")))

# Replace "NA" with 0 in the "checking_account" column
df_credit = df_credit.withColumn("checking_account", when(col("checking_account") == "NA", most_freq_checking)
                                  .otherwise(col("checking_account")))

df_credit.show()

# Create new features
df_credit = df_credit.withColumn("credit_amount_range", when(col("credit_amount") < 5000, "low")
                                  .when(col("credit_amount").between(5000, 10000), "medium")
                                  .otherwise("high"))
df_credit = df_credit.withColumn("age_group", when(col("age") < 30, "young")
                                  .when(col("age").between(30, 60), "middle-aged")
                                  .otherwise("senior"))



df_credit.show()

# ML flow